{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "color = sns.color_palette()\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def bar_plot(df, col, text = True, k = None, rot = 0):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x : pandas series\n",
    "    Returns:\n",
    "    seaborn barplot with text on top\n",
    "    \"\"\"\n",
    "    if k == None:\n",
    "        x = df[col].value_counts()\n",
    "    else:\n",
    "        x = df[col].value_counts()[:k]\n",
    "    ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
    "    plt.title(\"# per class\")\n",
    "    plt.ylabel('# of Occurrences', fontsize=12)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    #adding the text labels\n",
    "    if text:\n",
    "        rects = ax.patches\n",
    "        labels = x.values\n",
    "        for rect, label in zip(rects, labels):\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "    plt.xticks(rotation = rot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the root path\n",
    "root_dir = os.path.abspath('.')\n",
    "# set the data dir\n",
    "data_dir = '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (19906, 2)\n",
      "Test shape : (6636, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape :\",train.shape)\n",
    "print(\"Test shape :\",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(df, main_folder, folder_name):\n",
    "    temp = []\n",
    "    for index,img_name in enumerate(df.ID):\n",
    "        if index % 1000 == 0:\n",
    "            print ('Index :',index)\n",
    "        img_path = os.path.join(data_dir, main_folder, folder_name, img_name)\n",
    "        img = imread(img_path)\n",
    "        img = imresize(img, (32, 32))\n",
    "        img = img.astype('float32')\n",
    "        temp.append(img)\n",
    "\n",
    "    return np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 0\n",
      "Index : 1000\n",
      "Index : 2000\n",
      "Index : 3000\n",
      "Index : 4000\n",
      "Index : 5000\n",
      "Index : 6000\n",
      "Index : 7000\n",
      "Index : 8000\n",
      "Index : 9000\n",
      "Index : 10000\n",
      "Index : 11000\n",
      "Index : 12000\n",
      "Index : 13000\n",
      "Index : 14000\n",
      "Index : 15000\n",
      "Index : 16000\n",
      "Index : 17000\n",
      "Index : 18000\n",
      "Index : 19000\n",
      "CPU times: user 15 s, sys: 1.85 s, total: 16.9 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# resize all the images 32 x 32 (training set), usually takes ~ 4-5 min (CPU)\n",
    "train_x = resize_img(train,\"train\" ,\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 0\n",
      "Index : 1000\n",
      "Index : 2000\n",
      "Index : 3000\n",
      "Index : 4000\n",
      "Index : 5000\n",
      "Index : 6000\n"
     ]
    }
   ],
   "source": [
    "test_x = resize_img(test,\"test\" ,\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 600\n",
    "output_num_units = 3\n",
    "num_filter = 100\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## Input Layer\n",
    "model.add(InputLayer(input_shape=input_num_units))\n",
    "\n",
    "## Convolutional layer\n",
    "model.add(Conv2D(num_filter, (3, 3), activation='relu', input_shape=input_num_units))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(int(num_filter * 0.5), (3, 3), activation='relu', input_shape=(10, 10, 100)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(int(num_filter * 0.3), (3, 3), activation='relu', input_shape=(1, 1, 10)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_num_units, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(int(hidden_num_units * 0.2), activation='relu'))\n",
    "model.add(Dense(units=output_num_units, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 100)       2800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 50)        45050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 30)          13530     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               288600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               72120     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 363       \n",
      "=================================================================\n",
      "Total params: 422,463\n",
      "Trainable params: 422,463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17915 samples, validate on 1991 samples\n",
      "Epoch 1/30\n",
      "17915/17915 [==============================] - 6s 345us/step - loss: 0.8937 - acc: 0.5814 - val_loss: 0.8258 - val_acc: 0.6238\n",
      "Epoch 2/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.8027 - acc: 0.6397 - val_loss: 0.7516 - val_acc: 0.6796\n",
      "Epoch 3/30\n",
      "17915/17915 [==============================] - 2s 105us/step - loss: 0.7523 - acc: 0.6691 - val_loss: 0.7111 - val_acc: 0.6951\n",
      "Epoch 4/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.7175 - acc: 0.6833 - val_loss: 0.6902 - val_acc: 0.7057\n",
      "Epoch 5/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.6943 - acc: 0.6941 - val_loss: 0.6854 - val_acc: 0.7102\n",
      "Epoch 6/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.6724 - acc: 0.7064 - val_loss: 0.6716 - val_acc: 0.7027\n",
      "Epoch 7/30\n",
      "17915/17915 [==============================] - 2s 105us/step - loss: 0.6565 - acc: 0.7158 - val_loss: 0.6949 - val_acc: 0.6966\n",
      "Epoch 8/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.6399 - acc: 0.7238 - val_loss: 0.6224 - val_acc: 0.7323\n",
      "Epoch 9/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.6237 - acc: 0.7294 - val_loss: 0.6247 - val_acc: 0.7338\n",
      "Epoch 10/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.6067 - acc: 0.7398 - val_loss: 0.6518 - val_acc: 0.7228\n",
      "Epoch 11/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.5920 - acc: 0.7470 - val_loss: 0.6005 - val_acc: 0.7479\n",
      "Epoch 12/30\n",
      "17915/17915 [==============================] - 2s 105us/step - loss: 0.5753 - acc: 0.7507 - val_loss: 0.6085 - val_acc: 0.7378\n",
      "Epoch 13/30\n",
      "17915/17915 [==============================] - 2s 106us/step - loss: 0.5632 - acc: 0.7587 - val_loss: 0.5836 - val_acc: 0.7589\n",
      "Epoch 14/30\n",
      "17915/17915 [==============================] - 2s 106us/step - loss: 0.5486 - acc: 0.7675 - val_loss: 0.5893 - val_acc: 0.7539\n",
      "Epoch 15/30\n",
      "17915/17915 [==============================] - 2s 105us/step - loss: 0.5350 - acc: 0.7744 - val_loss: 0.5815 - val_acc: 0.7629\n",
      "Epoch 16/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.5163 - acc: 0.7822 - val_loss: 0.5733 - val_acc: 0.7725\n",
      "Epoch 17/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.5044 - acc: 0.7850 - val_loss: 0.5646 - val_acc: 0.7700\n",
      "Epoch 18/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.4855 - acc: 0.7959 - val_loss: 0.5839 - val_acc: 0.7629\n",
      "Epoch 19/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.4817 - acc: 0.7979 - val_loss: 0.5513 - val_acc: 0.7800\n",
      "Epoch 20/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.4679 - acc: 0.8050 - val_loss: 0.5684 - val_acc: 0.7700\n",
      "Epoch 21/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.4604 - acc: 0.8088 - val_loss: 0.5816 - val_acc: 0.7695\n",
      "Epoch 22/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.4473 - acc: 0.8152 - val_loss: 0.5653 - val_acc: 0.7775\n",
      "Epoch 23/30\n",
      "17915/17915 [==============================] - 2s 106us/step - loss: 0.4280 - acc: 0.8221 - val_loss: 0.5621 - val_acc: 0.7840\n",
      "Epoch 24/30\n",
      "17915/17915 [==============================] - 2s 106us/step - loss: 0.4227 - acc: 0.8228 - val_loss: 0.5714 - val_acc: 0.7785\n",
      "Epoch 25/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.4125 - acc: 0.8276 - val_loss: 0.5744 - val_acc: 0.7755\n",
      "Epoch 26/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.4103 - acc: 0.8309 - val_loss: 0.5623 - val_acc: 0.7855\n",
      "Epoch 27/30\n",
      "17915/17915 [==============================] - 2s 103us/step - loss: 0.3953 - acc: 0.8374 - val_loss: 0.5563 - val_acc: 0.7926\n",
      "Epoch 28/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.3823 - acc: 0.8419 - val_loss: 0.5785 - val_acc: 0.7850\n",
      "Epoch 29/30\n",
      "17915/17915 [==============================] - 2s 104us/step - loss: 0.3829 - acc: 0.8434 - val_loss: 0.5708 - val_acc: 0.7780\n",
      "Epoch 30/30\n",
      "17915/17915 [==============================] - 2s 105us/step - loss: 0.3642 - acc: 0.8535 - val_loss: 0.5623 - val_acc: 0.7805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecff38f898>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 1s 54us/step\n",
      "6636/6636 [==============================] - 0s 49us/step\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict_classes(train_x, verbose=1)\n",
    "pred = model.predict_classes(test_x, verbose=1)\n",
    "pred = lb.inverse_transform(pred)\n",
    "\n",
    "test['Class'] = pred\n",
    "test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
